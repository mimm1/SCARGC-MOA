package moa.labelscarcity;

import com.github.javacliparser.FlagOption;
import com.github.javacliparser.IntOption;
import com.github.javacliparser.FloatOption;
import com.github.javacliparser.ListOption;
import com.github.javacliparser.Option;
import com.github.javacliparser.MultiChoiceOption;
import com.yahoo.labs.samoa.instances.Attribute;
import com.yahoo.labs.samoa.instances.DenseInstance;
import com.yahoo.labs.samoa.instances.Instance;
import com.yahoo.labs.samoa.instances.Instances;
import com.yahoo.labs.samoa.instances.InstancesHeader;
import com.yahoo.labs.samoa.instances.MultiLabelInstance;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Vector;

import moa.classifiers.AbstractClassifier;
import moa.classifiers.Classifier;
import moa.classifiers.MultiClassClassifier;
import moa.core.Measurement;
import moa.evaluation.LearningPerformanceEvaluator;
import moa.evaluation.MeasureCollection;
import moa.evaluation.MembershipMatrix;
import moa.gui.visualization.DataPoint;
import moa.labelscarcity.HDWM.HTBaseLearner;
import moa.options.AbstractClassOption;
import moa.options.ClassOption;
import weka.core.Utils;


import java.util.ArrayList;
import java.util.List;
import moa.classifiers.SSLAbstractClassifier;
import moa.classifiers.SSLClassifier;
import moa.classifiers.core.attributeclassobservers.AttributeClassObserver;
import moa.classifiers.core.attributeclassobservers.GaussianNumericAttributeClassObserver;
import moa.classifiers.core.attributeclassobservers.NominalAttributeClassObserver;
import moa.classifiers.core.driftdetection.ChangeDetector;
import moa.cluster.Cluster;
import moa.cluster.Clustering;
import moa.cluster.SphereCluster;
import moa.clusterers.AbstractClusterer;
import moa.clusterers.ClusterGenerator;
import moa.clusterers.Clusterer;
import moa.clusterers.clustream.ClustreamKernel;
import moa.clusterers.outliers.MyBaseOutlierDetector;
import moa.core.AutoExpandVector;
import moa.core.DoubleVector;
import moa.core.Example;
import moa.core.FastVector;
import moa.core.InstanceExample;
import moa.core.Measurement;
import moa.core.ObjectRepository;
import moa.options.ClassOption;
import moa.streams.ExampleStream;
import moa.streams.InstanceStream;
import moa.streams.clustering.ClusteringStream;
import moa.tasks.TaskMonitor;
import weka.core.Utils;
import moa.labelscarcity.mCentroid;

/**
 * SCARGC Implementation 
 *
 * @author Mobin Idrees (mmadrees@uod.edu.sa)
 * @supervisor Dr. Frederic Stahl (f.t.stahl@reading.ac.uk)  
 * 
 * Souza, V. M., Silva, D. F., Gama, J., & Batista, G. E. (2015, June). 
 * Data stream classification guided by clustering on nonstationary environments and 
 * extreme verification latency. In Proceedings of the 2015 SIAM International 
 * Conference on Data Mining (pp. 873-881). Society for Industrial and Applied Mathematics.

 */

public class SCARGC extends SSLAbstractClassifier {
	private static final long serialVersionUID = 1L;
	
	 // Classifier Variables
    public ClassOption baseLearnerOption = new ClassOption("baseLearner", 'l',
            "Base classifiers to train.", Classifier.class, "bayes.NaiveBayes");
    
    
	// Prelabeling option
    public MultiChoiceOption prelableing = new MultiChoiceOption(
            "prelableingMethod", 'x', "prediction Option", new String[]{
            		"No Prelabeling", "Use Self Learning", "Clustering", "Active Switching"},
            new String[]{"No Prelabeling ",
                "Use Self Learning", "Clustering","Active Switching"
            }, 2);
    
	// Prediction option
    public MultiChoiceOption Prediction = new MultiChoiceOption(
            "PredictionMethod", 'y', "prediction Option", new String[]{
            		"Base Classifier", "Clustering","Switching of Clusters and Classifiers"},
            new String[]{"Base Classifier", "Clustering","Switching of Clusters and Classifiers"
            }, 1);
	   
    protected DoubleVector observedClassDistribution;
    protected AutoExpandVector<AttributeClassObserver> attributeObservers;
 
    // Clustering Variables
    private ExampleStream m_stream0;

    /* the measure collections contain all the measures */
    private MeasureCollection[] m_measures0 = null;
    private MeasureCollection[] m_measures1 = null;
    
    /* all possible clusterings */
    //not pretty to have all the clusterings, but otherwise we can't just redraw clusterings
    private Clustering gtClustering0 = null;
    private Clustering macro0 = null;
    private Clustering micro0 = null;
    
    protected AbstractClusterer[] clusterseed;
	protected int[][] boundarylabeled;
	protected int trainSize;


    protected ArrayList<AbstractClusterer> clusterer = new ArrayList<>();
    protected ArrayList<Clustering> foundClustering = new ArrayList<>();
	protected ArrayList<Double> cluster_weights = new ArrayList<>();
	
	ArrayList<mCentroid> GT_Centroids = new ArrayList<mCentroid>(); 
	ArrayList<mCentroid> macro_Centroids = new ArrayList<mCentroid>(); 
	ArrayList<mCentroid> micro_Centroids = new ArrayList<mCentroid>(); 

	mCentroid gtcentroid; 

    /* amount of relevant instances; older instances will be dropped;
    creates the 'sliding window' over the stream;
    is strongly connected to the decay rate and decay threshold*/
    private int batch_size;
    
	protected int num_classes;


    /* Base clustering option
	
	   public ListOption clusturerListOption = new ListOption(
	           "clusturer",
	            'q',
	            "The cluster to combine.",
	            new ClassOption("clusturer", ' ', "", Clusterer.class,
	            "ClusterGenerator"),
	            new Option[]{
	                new ClassOption("", ' ', "", Clusterer.class,
	                "ClusterGenerator"),
	                new ClassOption("", ' ', "", Clusterer.class,
	                "clustream.WithKmeans"),
	                new ClassOption("", ' ', "", Clusterer.class, 
	                "clustream.Clustream")},
	            ',');
*/
	public ListOption clusturerListOption = new ListOption(
	           "clusturer",
	            'q',
	            "The cluster to combine.",
	            new ClassOption("clusturer", ' ', "", Clusterer.class,
	            "clustream.Clustream -k 49"),
	            new Option[]{
	                new ClassOption("", ' ', "", Clusterer.class,
	                "clustream.Clustream -k 49"),
	                },
	            ',');
	
    
    public IntOption periodOption = new IntOption("period", 'p',
            "Period between Learner removal, creation, and weight update.", 50,
            1, Integer.MAX_VALUE);

	protected long epochs=0; 
	protected long testepochs=1; 

    protected int clusterbagSize;
	protected int labelAssigned=0;
	protected int correctlabelAssigned=0;
	protected int clusterCount=0;

	protected double correctlabelAssignedRatio=0.0;
	
    LinkedList<DataPoint> pointBuffer= null;
    LinkedList<DataPoint> labeledData= null;


    
    ArrayList<DataPoint> pointarray = null;

    
	private Classifier classifier_GT;
	private Classifier classifier_CLA;
	private Classifier classifier_CLU;


	private boolean foundboundary;
	
	private boolean pre_labeling_Started;
	protected double GT_ACC, CLU_ACC = 0,CLA_ACC = 0,Final_ACC=0,CLU_ACC_pre = 0,CLA_ACC_pre = 0;
	private LearningPerformanceEvaluator Final_evaluator,GT_evaluator, CLA_evaluator,CLU_evaluator,CLA_pre_evaluator,CLU_pre_evaluator;

	private int labeling_state = 0;
	
	 boolean overlap;

	    @Override
	    public void trainOnInstanceImpl(Instance inst) {
			

	         this.epochs++;

	    		//Instance is labeled
	     		
	    	  	DataPoint point0 = new DataPoint(inst,(int) this.epochs);

	     		labeledData.add(point0);
	    	
	           
	       }

	
    @Override
    public double[] getVotesForInstance(Instance inst) {
    	
    	if(testepochs == 1 || testepochs == 2 ||  testepochs == 3  )
    		System.out.println(testepochs + " , " + inst);
    	if(testepochs == 4  )
    		System.out.println(" .. " );
    	if(testepochs == 298 || testepochs == 299 ||  testepochs == 300  )
    		System.out.println(testepochs + " , " + inst);
    	
        initClustering(inst, testepochs);

        if (this.testepochs % batch_size  == 0 ) 
        {
  	          ProcessClustering();
  	          calculateNewLabeledData();   
        }
        
   	 double[] Pr_cluster = new double[num_classes];

        if (this.trainingWeightSeenByModel > 0.0) 
        	Pr_cluster = knnClassification(inst);
        	
        this.testepochs++;
        return Pr_cluster;

     }
    

	private void calculateNewLabeledData() {
		double[] Pr_cluster;

	
		labeledData.clear();
		
		for (int i = 0; i < pointBuffer.size(); i++) {
			
			Pr_cluster = getClusterWeightedVote(pointBuffer.get(i));
			if(Utils.sum(Pr_cluster) >0) { // make sure the prediction is not 0,0

			Instance inst= InstancePreLabeling(Pr_cluster,pointBuffer.get(i), CLU_pre_evaluator,1);  // 1=update cluster ACC 
			labeledData.add((DataPoint) inst);
			}
			else
			{
	            System.out.println("prediction 0:0");

			}
			
			
			//pointBuffer.clear();
		
        }
		
		
		
		
	}

	public void ClusterLearning(Instance inst) {
		double[] Pr_cluster;
		Pr_cluster = getClusterWeightedVote(inst);
		if(Utils.sum(Pr_cluster) >0) { // make sure the prediction is not 0,0
			   	   
		InstancePreLabeling(Pr_cluster,inst, CLU_pre_evaluator,1);  // 1=update cluster ACC 

		}
	}
    
    
    //Clustering methods
	private Instance InstancePreLabeling(double[] pr, Instance inst, LearningPerformanceEvaluator Pre_evaluator, int i) {
	      //cluster size, i.e. when cluster has formed and for only instances marked as unlabeled
		pre_labeling_Started = true;
		InstanceExample example = new InstanceExample(inst);
		example.instance.AssignClassLabel(inst.getTrueLabel());

		//if(!checkNoise(inst))
	     //  System.out.println("Noise Label");
		Pre_evaluator.addResult(example, pr);
		Final_ACC = Pre_evaluator.getPerformanceMeasurements()[1].getValue();
		//if(Pre_evaluator.getPerformanceMeasurements()[1].getValue() < 100) {
		if(i == 1)
			CLU_ACC_pre = Pre_evaluator.getPerformanceMeasurements()[1].getValue();
		else
			CLA_ACC_pre = Pre_evaluator.getPerformanceMeasurements()[1].getValue();
		//}
		//isInstance of 
      //System.out.println("Started Assigning Labels");

	    inst.setClassValue(Utils.maxIndex(pr));

		this.labelAssigned ++;
		//inst.AssignClassLabel(Utils.maxIndex(Pr_cluster));
		 
		if(Utils.maxIndex(pr) == inst.getTrueLabel() )
			correctlabelAssigned++;
		correctlabelAssignedRatio = ((double)correctlabelAssigned/(double)labelAssigned)*100; 	   

//if (correctlabelAssignedRatio <100 && this.epochs > 1000)
	//System.out.println("First Wrong");
		
		 inst.setPrelabelStatus(true);
		 
		 return inst;
		
	}

	public double[] getClusterWeightedVote(Instance inst) {

        double[] Pr_cluster = new double[num_classes];
        
	    SphereCluster Kernel = null;
	    SphereCluster closestKernel = null;
	    
	 //   if (checkoverlap() == true)
	   // 	return classifier_CLA.getVotesForInstance(inst);
	   // else
	   // {

			for ( int i = 0; i < foundClustering.size(); i++ ) { 

				
	 	    Clustering c = foundClustering.get(i);
	 	    if(c!=null) {
			double minDistance = Double.MAX_VALUE;

			for ( int j = 0; j < c.size(); j++ ) {
				Kernel = (SphereCluster) c.get(j);
				
				double distance =  Kernel.getCenterDistance(inst) ; 
	
				if (distance < minDistance  ) {
				   minDistance = distance;
				   closestKernel=Kernel;

				} 
			}
	 	     	       			  
	 	    
            if(closestKernel != null) {

			double yHat_cluster = closestKernel.getId();

			 // if(yHat_cluster != -1 || minDistance <= Kernel.getRadius()  ) {

				  if(yHat_cluster != -1) {

				  Pr_cluster[(int) yHat_cluster] += 1;
				  
				  }
			  
			  }

           // }
            
	 	    }
		}

		return Pr_cluster;
	    //}
	}
	  
   	@Override
	public void Initialize(int sizeofbatch, double weight, int numofclasses , int t_size, LearningPerformanceEvaluator evaluator) {
   		   num_classes = numofclasses;
   		   batch_size = sizeofbatch;
	       boundarylabeled = new int[clusterer.size()][num_classes];
	       trainSize = t_size;
	       this.Final_evaluator = evaluator;
	       this.GT_evaluator= (LearningPerformanceEvaluator) evaluator.copy();
	       this.CLA_evaluator = (LearningPerformanceEvaluator) evaluator.copy();
	       this.CLU_evaluator = (LearningPerformanceEvaluator) evaluator.copy();
	       this.CLA_pre_evaluator = (LearningPerformanceEvaluator) evaluator.copy();
	       this.CLU_pre_evaluator = (LearningPerformanceEvaluator) evaluator.copy();


	     //  m_stream0_decay_threshold = m_stream0.getDecayThreshold();

	       //m_stream0_decay_rate = (Math.log(1.0/m_stream0_decay_threshold)/Math.log(2)/batch_size);
	       
	}

    private void initClustering(Instance inst, long timestamp) {
    	
	  	DataPoint point0 = new DataPoint(inst,(int) this.epochs);

     //	if(inst.getScarceStatus() == false && !checkNoise(inst)  ) {  //if instance is labeled use it for GT clusters 

		while(pointBuffer.size() > batch_size){
			pointBuffer.removeFirst();
        }
		
    		  	pointBuffer.add(point0);
    		 	
        		for (int i = 0; i < clusterer.size(); i++) {
              		Instance traininst = new DenseInstance(point0);
                               
                      if(clusterer.get(i).keepClassLabel())
                       traininst.setDataset(point0.dataset());
                      else
                    	  traininst.deleteAttributeAt(point0.classIndex());       
                       clusterer.get(i).trainOnInstanceImpl(traininst); 
        		 }
	}
    
	public double[] knnClassification(Instance testinst) {
			
		double distances[] = new double[labeledData.size()];
        double[] Pr_cluster = new double[num_classes+1];

		double minDist = Integer.MAX_VALUE;
		int bestPoint = 0;
		
		
		
		for (int i=0; i< labeledData.size(); i++){
			
			distances[i] = this.getDistance(testinst, labeledData.get(i));

		      if (distances[i]  < minDist) {
		          minDist = distances[i] ;
		          bestPoint = i;
		        }
		}
		
		
   			 
	    Pr_cluster[(int) labeledData.get(bestPoint).classValue()] += 1;

         if(labeledData.get(bestPoint).classValue() != testinst.classValue() )
         {
	       //System.out.println(testepochs + " error true class " + testinst.classValue() + " KNN " + labeledData.get(bestPoint).classValue());
	       
         }
	     

			  		
		return Pr_cluster;
		
	}

	private double getDistance(Instance point, Instance testinst){
    	 double sum=0;
         for (int i=0; i<point.numInputAttributes(); i++)
         {
             double diff = point.valueInputAttribute(i)-testinst.valueInputAttribute(i);
             sum += diff*diff;
         }
         return Math.sqrt(sum);
    }	
    	


	public void ProcessClustering() {
		
        boundarylabeled = new int[clusterer.size()][num_classes];
	    pointarray = new ArrayList<DataPoint>(pointBuffer);

	    // find centroids

	    
	    Centroids(pointBuffer);
	    
	    
    	gtClustering0 = new Clustering(labeledData);
	
	
	 
	 GT_Centroids.clear();
	for (int i = 0; i < gtClustering0.size(); i++) {
		// System.out.println(gtClustering0.get(i).getId() + " C " + gtClustering0.get(i).getCenter()[0]);

		 gtcentroid = new mCentroid(gtClustering0.get(i).getCenter(), gtClustering0.get(i).getGroundTruth());
	     GT_Centroids.add(gtcentroid);}
	    if(gtClustering0 == null){
	    

		}
		
		clusterCount = gtClustering0.size();
		 if(clusterCount == 0 )
			 return;
		// Loop over the Clusterers
		foundClustering.clear();
		

		for (int i = 0; i < this.clusterer.size(); i++) {
			
			AbstractClusterer cluster = (AbstractClusterer) clusterer.get(i);
			
			 if(gtClustering0!= null){
		            if(cluster instanceof ClusterGenerator)
		                ((ClusterGenerator) cluster).setSourceClustering(gtClustering0);
		        }

				macro0 = cluster.getClusteringResult();

				
				
				// need boundary labeling here for macro0 from GTclustering
				
			     //macro0 = gtClustering0;

		        if(cluster.implementsMicroClusterer()){
		            micro0 = cluster.getMicroClusteringResult();
		            
		            
		            if(macro0 == null && micro0 != null){
		                //TODO: we need a Macro Clusterer Interface and the option for kmeans to use the non optimal centers
		                macro0 = moa.clusterers.KMeans.gaussianMeans(gtClustering0, micro0);
		            }
		          //label boundaries here using instances in the pointarray
					//if(macro0!= null && macro0.size() >0)
					//LabelBoundaries(macro0,labeledData);
					 
		      
		            	foundClustering.add(macro0); 
		        }
		}

  
	}
	
   	private void LabelBoundaries(Clustering macro, LinkedList<DataPoint> labeledData) {
   		
   		
      	SphereCluster closestKernel = null;
        SphereCluster Kernel = null;

        //cluster size, i.e. when cluster has formed and for only instances marked as unlabeled
    
        for(int i =0; i < macro.size(); i++ ) {   // iterate over macro
       	 int closestCluster = 0;
       	 double minDistance = Double.MAX_VALUE; 
       	// System.out.println("macro "+ macro.get(i).getCenter()[0] + " centroids " + macro.get(i).getCenter()[1] );

       	 
 		double distances[] = new double[labeledData.size()];
        double[] Pr_cluster = new double[num_classes];

		
		double minDist = Integer.MAX_VALUE;
		int bestPoint = 0;
		
		for (int j=0; j< labeledData.size(); j++){
			distances[j] = this.getDistance(macro.get(i).getCenter(), labeledData.get(j));
		      if (distances[j]  < minDist) {
		          minDist = distances[j] ;
		          bestPoint = j;
		        }
		}
		

       	         
            macro.get(i).setGroundTruth(labeledData.get(bestPoint).classValue());
            macro.get(i).setId(labeledData.get(bestPoint).classValue());
            
            
            
    		
       	 
        }   // end iterate over macro
        

      
     
        
      } // GT Labeling 
	
	
	private double getDistance(double[] center, DataPoint testinst) {
		double distance = 0.0;
		//get the center through getCenter so subclass have a chance
		
		for (int i = 0; i < center.length; i++) {
			double d = center[i] - testinst.value(i);
			distance += d * d;
		}
		return Math.sqrt(distance);
	}

	public void Centroids(List<? extends Instance> points){
        HashMap<Integer, Integer> labelMap = classValues(points);
        int dim = points.get(0).dataset().numAttributes()-1;

        int numClasses = labelMap.size();
        int noiseLabel;
        
        Attribute classLabel = points.get(0).dataset().classAttribute();
        int lastLabelIndex = classLabel.numValues() - 1;
        if (classLabel.value(lastLabelIndex) == "noise") {
        	noiseLabel = lastLabelIndex;
        } else {
        	noiseLabel = -1;
        }

        ArrayList<Instance>[] sorted_points = (ArrayList<Instance>[]) new ArrayList[numClasses];
        ArrayList<Double>[] centers = (ArrayList<Double>[]) new ArrayList[numClasses];

        
        for (int i = 0; i < numClasses; i++) {
            sorted_points[i] = new ArrayList<Instance>();
            centers[i] = new ArrayList<Double>();

        }
        for (Instance point : points) {
            int clusterid = (int)point.classValue();
            if(clusterid == noiseLabel) continue;
            sorted_points[labelMap.get(clusterid)].add((Instance)point);
        }
        
        for (int i = 0; i < numClasses; i++) {
        	if(!sorted_points[i].isEmpty())
        	centers[i].addAll(findCentroids(sorted_points[i], numClasses))  ;
        }
		 
	}
	
	public ArrayList<Double> findCentroids(ArrayList<Instance> points, int numClasses){
		
         ArrayList<Double> tempcentroids =  new ArrayList<Double>();
   

        for (int i = 0; i < numClasses; i++) {
            ArrayList<Double> temp_points = (ArrayList<Double>) new ArrayList();
        	
        	for (Instance point : points) {
        		temp_points.add(point.value(i));
        	
        	}
        	
        	double m = median(temp_points);
        	tempcentroids.add(m);
        	
        }

		
		
return tempcentroids;
		

	}
	
    private Double median(ArrayList<Double> temp_points) {
    	
    	double m=0;
    	Collections.sort(temp_points);

    	if(temp_points.size()%2==1)
    	{
    		//m=a[((n+1)/2)-1];
    		m= temp_points.get(((temp_points.size()+1)/2)-1);
    	}
    	else
    	{
    		//m=(in[n/2-1]+in[n/2])/2;
    		m= (temp_points.get((temp_points.size()/2)-1) + temp_points.get(temp_points.size()/2))/2;

    		
    		//m=(a[n/2-1]+a[n/2])/2;
    	}
		return m;
	}


	/**
     * @param points 
     * @return an array with the min and max class label value
     */
    public static HashMap<Integer, Integer> classValues(List<? extends Instance> points){
        HashMap<Integer,Integer> classes = new HashMap<Integer, Integer>();
        int workcluster = 0;
        boolean hasnoise = false;
        for (int i = 0; i < points.size(); i++) {
            int label = (int) points.get(i).classValue();
            if(label == -1){
                hasnoise = true;
            }
            else{
                if(!classes.containsKey(label)){
                    classes.put(workcluster,workcluster);
                    workcluster++;
                }
            }
        }
        if(hasnoise)
            classes.put(-1,workcluster);
        return classes;
    }
	
	@Override
	public void prepareForUseImpl(TaskMonitor monitor,
	            ObjectRepository repository) {
   		
		classifier_GT = ((Classifier) getPreparedClassOption(this.baseLearnerOption)).copy();
		classifier_CLA = ((Classifier) getPreparedClassOption(this.baseLearnerOption)).copy();
		classifier_CLU = ((Classifier) getPreparedClassOption(this.baseLearnerOption)).copy();


		    Option[] clusterensembleBagOption = this.clusturerListOption.getList();
		         
	        this.clusterseed = new AbstractClusterer[clusterensembleBagOption.length];

            //for clustering
  	            
   	            pointBuffer= new LinkedList<DataPoint>();
   	            labeledData= new LinkedList<DataPoint>();


          
	            clusterbagSize = clusterensembleBagOption.length;
	          
	
		      
		      for (int i = 0; i < clusterbagSize; i++) {
	   	            
	   	         this.clusterseed[i]= (AbstractClusterer) (AbstractClusterer) ((ClassOption) clusterensembleBagOption[i]).materializeObject(monitor, repository);
	   	            clusterer.add(clusterseed[i]);
	   	            this.cluster_weights.add(1.0);
		   		
		   		
	   	        if (monitor.taskShouldAbort()) {
	                return;
	            }
	   	        
	            monitor.setCurrentActivity("Preparing clusrers " + (i + 1) + "...",
	                    -1.0);
	            this.clusterseed[i].prepareForUse(monitor, repository);
	            if (monitor.taskShouldAbort()) {
	                return;
	            }
		      }
		      
	       super.prepareForUseImpl(monitor, repository);
	    }

    @Override
    public void resetLearningImpl() {
    	
    	 this.observedClassDistribution = new DoubleVector();
         this.attributeObservers = new AutoExpandVector<AttributeClassObserver>(); 	

    }
     
    @Override
    public boolean isRandomizable() {
        return false;
    }

    @Override
    protected Measurement[] getModelMeasurementsImpl() {

        Measurement[] measurements = null;
        
        if(baseLearnerOption.getValueAsCLIString().toString().contains("Naive") || baseLearnerOption.getValueAsCLIString().toString().contains("Hoeffding") )
        {
            measurements = new Measurement[8];

            measurements[0] = new Measurement("members size", 1);
            measurements[1] = new Measurement("Drifts detected", 0);
            measurements[2] = new Measurement("Warnings detected", 0);
            measurements[3] = new Measurement("Labels Assigned", labelAssigned);
            measurements[4] = new Measurement("Correct Labels Assigned", correctlabelAssigned);
            measurements[5] = new Measurement("Ratio", correctlabelAssignedRatio );
            measurements[6] = new Measurement("Cluster Count", clusterCount);
            measurements[7] = new Measurement("Labeling State", labeling_state);

        }
        if(baseLearnerOption.getValueAsCLIString().toString().contains("HDWM"))

        {
        
        measurements = new Measurement[8];
        measurements[0] = new Measurement("members size", classifier_GT.getModelMeasurements()[2].getValue());
        measurements[1] = new Measurement("Drifts detected", classifier_GT.getModelMeasurements()[3].getValue());
        measurements[2] = new Measurement("Warnings detected", classifier_GT.getModelMeasurements()[4].getValue());
        measurements[3] = new Measurement("Labels Assigned", labelAssigned);
        measurements[4] = new Measurement("Correct Labels Assigned", correctlabelAssigned);
        measurements[5] = new Measurement("Ratio", correctlabelAssignedRatio );
        measurements[6] = new Measurement("Cluster Count", clusterCount);
        measurements[7] = new Measurement("Labeling State", labeling_state);

        }
        if(baseLearnerOption.getValueAsCLIString().toString().contains("DWM") || baseLearnerOption.getValueAsCLIString().toString().contains("Weighted"))
        {
            measurements = new Measurement[8];

            measurements[0] = new Measurement("members size", classifier_GT.getModelMeasurements()[2].getValue());
            measurements[1] = new Measurement("Drifts detected", 0);
            measurements[2] = new Measurement("Warnings detected", 0);
            measurements[3] = new Measurement("Labels Assigned", labelAssigned);
            measurements[4] = new Measurement("Correct Labels Assigned", correctlabelAssigned);
            measurements[5] = new Measurement("Ratio", correctlabelAssignedRatio );
            measurements[6] = new Measurement("Cluster Count", clusterCount);
            measurements[7] = new Measurement("Labeling State", labeling_state);

        }
          
      	 // System.out.println("D " + numberOfDrifts );
      // System.out.println(DriftLocation_global );

        return measurements;
  
    }

	@Override
    public void getModelDescription(StringBuilder out, int indent) {

    }

	@Override
	public ArrayList<AbstractClusterer> Getclusterer() {
		// TODO Auto-generated method stub
		return clusterer ;
	}
	@Override
	public ArrayList<Clustering> GetfoundClustering() {
		// TODO Auto-generated method stub
		return foundClustering ;
	}

	@Override
	public Clustering getMacro() {
		// TODO Auto-generated method stub
		return micro0;
	}
	
	@Override
	public ArrayList<DataPoint> getPointarray() {
		// TODO Auto-generated method stub
		return pointarray;
	}
	
	@Override
	public String getLearnerName() {
		// TODO Auto-generated method stub
		return baseLearnerOption.getValueAsCLIString().toString();
	}





	
}








